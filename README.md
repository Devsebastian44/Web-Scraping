# ğŸ•·ï¸ Web Scraping Tool

[![Python Version](https://img.shields.io/badge/python-3.8%2B-blue)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GitLab CI](https://img.shields.io/badge/gitlab-ci-%23181717.svg?logo=gitlab&logoColor=white)](https://about.gitlab.com/)

Herramienta profesional de **Web Scraping** desarrollada en Python para la extracciÃ³n automatizada de activos (JS, CSS) y el anÃ¡lisis de disponibilidad de enlaces en sitios web.


## ğŸ¯ Objetivo
Este proyecto busca proporcionar una utilidad eficiente y fÃ¡cil de usar para desarrolladores, analistas de datos y profesionales de ciberseguridad que necesiten auditar o extraer informaciÃ³n pÃºblica de pÃ¡ginas web de forma estructurada.

## ğŸ“‚ Estructura del Proyecto
La arquitectura del repositorio sigue estÃ¡ndares profesionales para facilitar la mantenibilidad y escalabilidad:

```text
Web-Scraping/
â”œâ”€â”€ data/           # Repositorio para salidas y datasets generados
â”œâ”€â”€ src/            # CÃ³digo fuente principal
â”‚   â””â”€â”€ scraping.py # Script principal de la aplicaciÃ³n
â”œâ”€â”€ .gitignore      # DefiniciÃ³n de archivos excluidos
â”œâ”€â”€ .gitlab-ci.yml  # ConfiguraciÃ³n de integraciÃ³n continua
â”œâ”€â”€ LICENSE         # Licencia MIT
â””â”€â”€ README.md       # DocumentaciÃ³n principal
```

## âš™ï¸ Requisitos
- **Lenguaje:** Python 3.8 o superior
- **Dependencias:**
  - `requests`: Manejo de solicitudes HTTP.
  - `beautifulsoup4`: AnÃ¡lisis de documentos HTML.

## ğŸš€ InstalaciÃ³n y Uso

1. **Clonar el repositorio:**
   ```bash
   git clone https://github.com/Devsebastian44/Web-Scraping.git
   cd Web-Scraping
   ```

2. **Instalar dependencias:**
   ```bash
   pip install requests beautifulsoup4
   ```

3. **Ejecutar la herramienta:**
   ```bash
   python src/scraping.py
   ```

## ğŸ› ï¸ Funcionalidades
- **ExtracciÃ³n de Activos:** Identifica y lista todos los archivos JavaScript y CSS vinculados a una URL.
- **AuditorÃ­a de Enlaces:** Clasifica enlaces en internos, externos y relativos, verificando su disponibilidad.
- **Reportes AutomÃ¡ticos:** Genera archivos de texto estructurados en carpetas dedicadas segÃºn el anÃ¡lisis.

## âš ï¸ Advertencia Ã‰tica
Esta herramienta debe utilizarse exclusivamente con fines educativos, de auditorÃ­a autorizada o sobre sitios que permitan el scraping segÃºn su archivo `robots.txt`. El autor no se hace responsable del mal uso de este software.

## ğŸ“œ Licencia
Este proyecto se distribuye bajo la **Licencia MIT**. SiÃ©ntete libre de usarlo, modificarlo y compartirlo.

---
*Desarrollado con â¤ï¸ por [Sebastian](https://github.com/Devsebastian44)*


